name: Update and Deploy HTML

on:
  schedule:
    - cron: '0 7 * * *'  # æ¯Žæ—¥16æ™‚ã«å®Ÿè¡Œ
  workflow_dispatch:

permissions:
  contents: write

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      codes-file: ${{ steps.setup-codes.outputs.codes-file }}
    steps:
      - name: Checkout ðŸ›ƒ
        uses: actions/checkout@v2
  
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create environment file
        run: |
          echo "# j-Quants API Configuration" >> .env
          echo "JQUANTS_REFRESH_TOKEN=${{ secrets.JQUANTS_REFRESH_TOKEN }}" >> .env
          echo "" >> .env
          echo "# Logging Configuration" >> .env
          echo "LOG_LEVEL=INFO" >> .env
          echo "LOG_FILE=logs/app.log" >> .env
          echo "" >> .env
          echo "# Scraping Configuration" >> .env
          echo "SCRAPING_DELAY=0.5" >> .env
          echo "MAX_RETRIES=2" >> .env
          echo "TIMEOUT=20" >> .env
          echo "" >> .env
          echo "# File Paths" >> .env
          echo "CODES_FILE=data/codes.csv" >> .env
          echo "OUTPUT_FILE=data/output.csv" >> .env
          echo "BACKUP_DIR=data/backup/" >> .env

      - name: Run stock code fetching
        id: setup-codes
        run: |
          export PYTHONPATH=$GITHUB_WORKSPACE
          python src/stock_code_fetcher_secure.py
          echo "codes-file=data/codes.csv" >> $GITHUB_OUTPUT

  scrape-data:
    runs-on: ubuntu-latest
    needs: setup
    steps:
      - name: Checkout ðŸ›ƒ
        uses: actions/checkout@v2
  
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Setup Chrome
        uses: browser-actions/setup-chrome@latest

      - name: Setup ChromeDriver
        uses: nanasess/setup-chromedriver@master

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create environment file
        run: |
          echo "# j-Quants API Configuration" >> .env
          echo "JQUANTS_REFRESH_TOKEN=${{ secrets.JQUANTS_REFRESH_TOKEN }}" >> .env
          echo "" >> .env
          echo "# Logging Configuration" >> .env
          echo "LOG_LEVEL=INFO" >> .env
          echo "LOG_FILE=logs/app.log" >> .env
          echo "" >> .env
          echo "# Scraping Configuration" >> .env
          echo "SCRAPING_DELAY=0.5" >> .env
          echo "MAX_RETRIES=2" >> .env
          echo "TIMEOUT=20" >> .env
          echo "" >> .env
          echo "# File Paths" >> .env
          echo "CODES_FILE=data/codes.csv" >> .env
          echo "OUTPUT_FILE=data/output.csv" >> .env
          echo "BACKUP_DIR=data/backup/" >> .env

      - name: Run parallel scraper with optimized settings
        run: |
          export PYTHONPATH=$GITHUB_WORKSPACE
          python src/scraper_parallel.py

      - name: Upload scraped data
        uses: actions/upload-artifact@v4
        with:
          name: scraped-data
          path: data/output.csv

  process-data:
    runs-on: ubuntu-latest
    needs: scrape-data
    steps:
      - name: Checkout ðŸ›ƒ
        uses: actions/checkout@v2
  
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download scraped data
        uses: actions/download-artifact@v4
        with:
          name: scraped-data
          path: data/

      - name: Create environment file
        run: |
          echo "# j-Quants API Configuration" >> .env
          echo "JQUANTS_REFRESH_TOKEN=${{ secrets.JQUANTS_REFRESH_TOKEN }}" >> .env
          echo "" >> .env
          echo "# Logging Configuration" >> .env
          echo "LOG_LEVEL=INFO" >> .env
          echo "LOG_FILE=logs/app.log" >> .env
          echo "" >> .env
          echo "# Scraping Configuration" >> .env
          echo "SCRAPING_DELAY=0.5" >> .env
          echo "MAX_RETRIES=2" >> .env
          echo "TIMEOUT=20" >> .env
          echo "" >> .env
          echo "# File Paths" >> .env
          echo "CODES_FILE=data/codes.csv" >> .env
          echo "OUTPUT_FILE=data/output.csv" >> .env
          echo "BACKUP_DIR=data/backup/" >> .env

      - name: Process data and generate visualizations
        run: |
          export PYTHONPATH=$GITHUB_WORKSPACE
          python src/data_processing.py
          python src/visualize.py
          python src/time_series_visualizer.py

      - name: Upload processed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: |
            data/
            docs/

  deploy:
    runs-on: ubuntu-latest
    needs: process-data
    steps:
      - name: Checkout ðŸ›ƒ
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: ./

      - name: Create environment file
        run: |
          echo "# j-Quants API Configuration" >> .env
          echo "JQUANTS_REFRESH_TOKEN=${{ secrets.JQUANTS_REFRESH_TOKEN }}" >> .env
          echo "" >> .env
          echo "# Logging Configuration" >> .env
          echo "LOG_LEVEL=INFO" >> .env
          echo "LOG_FILE=logs/app.log" >> .env
          echo "" >> .env
          echo "# Scraping Configuration" >> .env
          echo "SCRAPING_DELAY=0.5" >> .env
          echo "MAX_RETRIES=2" >> .env
          echo "TIMEOUT=20" >> .env
          echo "" >> .env
          echo "# File Paths" >> .env
          echo "CODES_FILE=data/codes.csv" >> .env
          echo "OUTPUT_FILE=data/output.csv" >> .env
          echo "BACKUP_DIR=data/backup/" >> .env

      - name: Update HTML and cleanup
        run: |
          export PYTHONPATH=$GITHUB_WORKSPACE
          python src/update_html.py
          python -c "
          from src.data_manager import DataManager
          manager = DataManager()
          manager.cleanup_old_files(keep_days=365)
          print('Old data cleanup completed')
          "

      - name: Set up Git credentials
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git remote set-url origin https://${{ secrets.PERSONAL_ACCESS_TOKEN }}@github.com/hiroshimaeasyryo/pbr_pjt.git

      - name: Deploy ðŸš€
        uses: JamesIves/github-pages-deploy-action@4.1.5
        with:
          branch: gh-pages
          folder: docs
          clean: true
          token: ${{ secrets.GITHUB_TOKEN }}